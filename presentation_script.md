# LuckyPets Logistics System - Presentation Script

## Introduction (30 seconds)
"Today I'll demonstrate our LuckyPets Logistics System, an event-driven microservice architecture built with Spring Boot and Apache Kafka. This system tracks pet shipments from creation to delivery, with real-time notifications and analytics."

## System Architecture Overview (1 minute)
"Our system consists of five microservices that communicate asynchronously via Kafka events:

1. Shipment Service - Creates shipments and publishes events
2. Scan Service - Records scans at different locations
3. Delivery Service - Processes deliveries when shipments reach their destination
4. Notification Service - Provides notifications for all shipment events
5. Analytics Service - Aggregates delivery data using Kafka Streams

Let me show you how they work together in a real scenario."

## Start the System (30 seconds)
"I'm starting all services using Docker Compose. This launches our microservices along with Kafka, Zookeeper, and PostgreSQL."

```bash
docker-compose up -d
docker-compose ps
```

"As you can see, all services are now running."

## End-to-End Demo (3 minutes)

### Step 1: Create Shipment
"First, I'll create a new shipment from Berlin to Munich using the Shipment Service REST API."

```bash
curl -X POST http://localhost:8081/api/v1/shipments \
  -H "Content-Type: application/json" \
  -d '{
    "origin": "Berlin",
    "destination": "Munich",
    "customerId": "customer123"
  }'
```

"The Shipment Service has created the shipment and published a ShipmentCreatedEvent to Kafka. Let's look at the logs:"

```bash
docker-compose logs -f shipmentservice
```

"You can see the event being published to the shipment-created topic."

### Step 2: Scan Shipment at Origin
"Now I'll scan the shipment at its origin in Berlin."

```bash
curl -X POST "http://localhost:8082/scans?shipmentId={shipmentId}&location=Berlin"
```

"The Scan Service has recorded the scan and published a ShipmentScannedEvent. Let's check the logs:"

```bash
docker-compose logs -f scanservice
```

"You can see the event being published to the shipment-scanned topic."

### Step 3: Scan Shipment at Destination
"Now the shipment has arrived at its destination in Munich. I'll scan it again:"

```bash
curl -X POST "http://localhost:8082/scans?shipmentId={shipmentId}&location=Munich"
```

"Since the scan location matches the destination, the Delivery Service automatically:
1. Updates the shipment status to DELIVERED
2. Publishes a ShipmentDeliveredEvent

Let's check the Delivery Service logs:"

```bash
docker-compose logs -f deliveryservice
```

"You can see the ShipmentDeliveredEvent being published."

### Step 4: Check Notifications
"Let's check the notifications generated by these events:"

```bash
curl -X GET http://localhost:8085/api/notifications
```

"The Notification Service has created notifications for each event in the shipment's lifecycle."

### Step 5: Check Analytics
"Finally, let's see how the Analytics Service processes delivery data:"

```bash
docker-compose logs -f analyticservice
```

"The Analytics Service uses Kafka Streams to aggregate deliveries by location and time window, publishing the results to the shipment-analytics topic."

## Kafka UI Demonstration (1 minute)
"We can also visualize the event flow using the Kafka UI. Let me open it at http://localhost:8080."

"Here you can see:
1. All our Kafka topics
2. The messages flowing through each topic
3. Consumer groups and their offsets

This gives us complete visibility into our event-driven system."

## Error Handling (Optional - 1 minute)
"Our system is also designed to handle errors gracefully. Let me demonstrate by scanning a non-existent shipment:"

```bash
curl -X POST "http://localhost:8082/scans?shipmentId=nonexistent&location=Berlin"
```

"As you can see, the service returns an appropriate error message."

"We can also demonstrate resilience by stopping a service and observing retry behavior:"

```bash
docker-compose stop notificationservice
# Create or scan a shipment
docker-compose start notificationservice
docker-compose logs -f notificationservice
```

"Notice how the service processes the backlog of events after restarting."

## Conclusion (30 seconds)
"To summarize, we've seen a complete flow through our event-driven microservice system:
1. Creating a shipment
2. Scanning it at different locations
3. Automatic delivery processing
4. Real-time notifications
5. Analytics generation

This architecture gives us scalability, resilience, and loose coupling between services, making it ideal for our logistics operations."

"Any questions?"